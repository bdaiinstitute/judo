#include <pybind11/pybind11.h>
#include <pybind11/stl.h>
#include <pybind11/numpy.h>
#include <mujoco/mujoco.h>

#include "onnx_rollout.h"
#include "onnx_interface_wrapped.h"

namespace py = pybind11;

static std::vector<const mjModel*> getModelVector(const py::list& python_models) {
    std::vector<const mjModel*> model_vector;
    model_vector.reserve(python_models.size());
    for (auto&& item : python_models) {
        auto ptr = item.attr("_address").cast<std::uintptr_t>();
        model_vector.push_back(reinterpret_cast<const mjModel*>(ptr));
    }
    return model_vector;
}

static std::vector<mjData*> getDataVector(const py::list& python_data) {
    std::vector<mjData*> data_vector;
    data_vector.reserve(python_data.size());
    for (auto&& item : python_data) {
        auto ptr = item.attr("_address").cast<std::uintptr_t>();
        data_vector.push_back(reinterpret_cast<mjData*>(ptr));
    }
    return data_vector;
}

PYBIND11_MODULE(_judo_cpp, m) {
    // Function to shutdown persistent thread pool
    m.def("shutdown_thread_pool",
          []() {
              ThreadPoolManager::instance().shutdown();
          },
          R"doc(
Shutdown the persistent thread pool.

Call this function to clean up the persistent thread pool when done with rollouts.
The pool will be automatically recreated on the next call to persistent_cpp_rollout.
)doc");

    // ONNX Policy-driven rollout
    m.def("onnx_policy_rollout",
          [](const py::list& models,
             const py::list& data,
             const py::array_t<double>& x0,
             int horizon,
             const std::string& onnx_model_path,
             const py::array_t<double>& commands = py::array_t<double>())
          {
              // turn Python lists into vectors of mjModel*/mjData*
              auto models_cpp = getModelVector(models);
              auto data_cpp   = getDataVector(data);

              // call into your C++ implementation
              return ONNXPolicyRollout(models_cpp, data_cpp, x0, horizon, onnx_model_path, commands);
          },
          py::arg("models"),
          py::arg("data"),
          py::arg("x0"),
          py::arg("horizon"),
          py::arg("onnx_model_path"),
          py::arg("commands") = py::array_t<double>(),
          R"doc(
Run policy-driven parallel MuJoCo rollouts where ONNX model generates actions.

The ONNX model receives per-step commands (if provided) and produces actions that are applied to the simulation.

Args:
    models:                 length-B list of mujoco._structs.MjModel
    data:                   length-B list of mujoco._structs.MjData
    x0:                     2D array of shape (B, nq+nv), batched initial [qpos;qvel]
    horizon:                Number of simulation steps to run
    onnx_model_path:        Path to the ONNX policy model file
    state_history_length:   Number of previous states to track (default: 10)
    action_history_length:  Number of previous actions to track (default: 5)
    inference_frequency:    Run inference every N steps (default: 1, every step)
    additional_inputs:      Additional inputs (goals, commands) - shape (B, dim) or (dim,)

Returns:
    tuple of three np.ndarray:
      states  -> shape (B, horizon+1, nq+nv) - MuJoCo states (includes initial state)
      actions -> shape (B, horizon, nu) - actions generated by policy
      sensors -> shape (B, horizon, nsensordata) - sensor data
)doc");

    // Persistent ONNX Policy-driven rollout
    m.def("persistent_onnx_policy_rollout",
          [](const py::list& models,
             const py::list& data,
             const py::array_t<double>& x0,
             int horizon,
             const std::string& onnx_model_path,
             const py::array_t<double>& commands = py::array_t<double>())
          {
              // turn Python lists into vectors of mjModel*/mjData*
              auto models_cpp = getModelVector(models);
              auto data_cpp   = getDataVector(data);

              // call into your C++ implementation with persistent thread pool
              return PersistentONNXPolicyRollout(models_cpp, data_cpp, x0, horizon, onnx_model_path, commands);
          },
          py::arg("models"),
          py::arg("data"),
          py::arg("x0"),
          py::arg("horizon"),
          py::arg("onnx_model_path"),
          py::arg("commands") = py::array_t<double>(),
          R"doc(
Run policy-driven parallel MuJoCo rollouts using persistent thread pool for better performance.

Each thread maintains its own ONNX model instance. The ONNX model receives per-step commands (if provided)
and produces actions that are applied to the simulation.

Args:
    models:                 length-B list of mujoco._structs.MjModel
    data:                   length-B list of mujoco._structs.MjData
    x0:                     2D array of shape (B, nq+nv), batched initial [qpos;qvel]
    horizon:                Number of simulation steps to run
    onnx_model_path:        Path to the ONNX policy model file
    state_history_length:   Number of previous states to track (default: 10)
    action_history_length:  Number of previous actions to track (default: 5)
    inference_frequency:    Run inference every N steps (default: 1, every step)
    additional_inputs:      Additional inputs (goals, commands) - shape (B, dim) or (dim,)

Returns:
    tuple of three np.ndarray:
      states  -> shape (B, horizon+1, nq+nv) - MuJoCo states (includes initial state)
      actions -> shape (B, horizon, nu) - actions generated by policy
      sensors -> shape (B, horizon, nsensordata) - sensor data
)doc");

}
